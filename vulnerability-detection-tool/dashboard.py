# dashboard.py - FOSS-CHERUB Complete Security Scanner
# Semgrep + Tree-sitter + AI + CVE/CWE Database + CWE Classification

import streamlit as st
import requests
import pandas as pd
import tempfile
import git
import subprocess
import json
from pathlib import Path
import shutil
import os
import zipfile
import tarfile
import io

# Database integration
try:
    from db_connector import CVEDatabase
    db = CVEDatabase()
    DB_AVAILABLE = True
except Exception as e:
    db = None
    DB_AVAILABLE = False

# CWE Classifier integration
try:
    from cwe_classifier import enrich_findings_with_cwe
    CWE_CLASSIFIER_AVAILABLE = True
except Exception as e:
    CWE_CLASSIFIER_AVAILABLE = False
    print(f"CWE Classifier not available: {e}")

# ==================== CONFIGURATION ====================
API_ENDPOINT = "http://localhost:8080"
BATCH_SIZE = 8
SEVERITY_ORDER = {
    'CRITICAL': 0,
    'HIGH': 1,
    'MEDIUM': 2,
    'WARNING': 3,
    'LOW': 4,
    'INFO': 5,
}

st.set_page_config(
    layout="wide",
    page_title="FOSS-CHERUB Security Scanner",
    page_icon="F",
)

# ==================== TREE-SITTER SETUP ====================
try:
    from tree_sitter import Language, Parser
    import tree_sitter_python as tspython
    import tree_sitter_c as tsc
    import tree_sitter_cpp as tscpp
    import tree_sitter_java as tsjava
    import tree_sitter_javascript as tsjs
    TREE_SITTER_AVAILABLE = True
except ImportError:
    TREE_SITTER_AVAILABLE = False

# ==================== SESSION STATE ====================
for key, default in {
    'view': 'scan',
    'results': None,
    'selected_finding': None,
    'repo_url': "",
    'repo_path': None,
    'detection_score': {"detected": 0, "total": 0},
    'ast_cache': {},
    'current_scan_id': None,
    'filters': {
        'severity': ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'INFO', 'WARNING'],
        'source': 'All',
        'zero_day_risk': 'All',
        'search': ''
    }
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# ==================== HELPER FUNCTIONS ====================

def normalize_cwe(cwe_value):
    if isinstance(cwe_value, list):
        return ', '.join(str(c) for c in cwe_value) if cwe_value else "N/A"
    return str(cwe_value) if cwe_value else "N/A"

def normalize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    if 'CWE' in df.columns:
        df['CWE'] = df['CWE'].apply(normalize_cwe)
    if 'Line' in df.columns:
        df['Line'] = df['Line'].astype(str)
    for col in ['Source', 'File Path', 'Vulnerability', 'Severity', 'Zero-Day Risk']:
        if col in df.columns:
            df[col] = df[col].astype(str)
    return df

def apply_filters(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    filtered = df.copy()
    if st.session_state.filters['severity']:
        filtered = filtered[filtered['Severity'].isin(st.session_state.filters['severity'])]
    if st.session_state.filters['source'] != 'All':
        filtered = filtered[
            filtered['Source'].str.contains(st.session_state.filters['source'], case=False, na=False)
        ]
    if st.session_state.filters['zero_day_risk'] != 'All':
        filtered = filtered[filtered['Zero-Day Risk'] == st.session_state.filters['zero_day_risk']]
    if st.session_state.filters['search']:
        search_term = st.session_state.filters['search'].lower()
        mask = (
            filtered['File Path'].str.lower().str.contains(search_term, na=False) |
            filtered['Vulnerability'].str.lower().str.contains(search_term, na=False) |
            filtered['CWE'].str.lower().str.contains(search_term, na=False)
        )
        filtered = filtered[mask]
    return filtered

def get_language(file_path: Path) -> str:
    mapping = {
        '.c': 'C', '.h': 'C',
        '.cpp': 'C++', '.hpp': 'C++', '.cxx': 'C++',
        '.java': 'Java',
        '.py': 'Python',
        '.js': 'JavaScript',
        '.php': 'PHP',
    }
    return mapping.get(file_path.suffix.lower(), 'Unknown')

def enrich_llm_finding_with_ai(finding: dict) -> dict:
    if finding.get('Line') == 'N/A' or not finding.get('Line'):
        finding['Line'] = 'Multiple'
    if 'Zero-Day Risk' not in finding:
        vuln_text = str(finding.get('Vulnerability', '')).lower()
        high_risk = ['eval', 'exec', 'deserialize', 'memory', 'buffer', 'injection', 'rce', 'remote']
        if any(p in vuln_text for p in high_risk):
            finding['Zero-Day Risk'] = 'High'
        elif finding.get('Severity') in ['CRITICAL', 'HIGH']:
            finding['Zero-Day Risk'] = 'Medium'
        else:
            finding['Zero-Day Risk'] = 'Low'
    return finding

def calculate_detection_score(findings_df: pd.DataFrame) -> dict:
    semgrep = len(findings_df[findings_df['Source'].str.contains('Semgrep', na=False)])
    ai = len(findings_df[findings_df['Source'].str.contains('AI', na=False)])
    treesitter = len(findings_df[findings_df['Source'].str.contains('Tree-sitter', na=False)])
    detected = (semgrep > 0) + (ai > 0) + (treesitter > 0)
    return {"detected": detected, "total": 3, "findings_count": len(findings_df)}

# ==================== TREE-SITTER ANALYSIS ====================

def get_parser_for_language(language: str):
    """Get tree-sitter parser (v0.22+ API)"""
    if not TREE_SITTER_AVAILABLE:
        return None

    try:
        lang = language.strip().lower()
        lang_map = {
            'python': tspython.language(),
            'c': tsc.language(),
            'c header': tsc.language(),
            'c++': tscpp.language(),
            'c++ header': tscpp.language(),
            'java': tsjava.language(),
            'javascript': tsjs.language(),
        }

        if lang in lang_map:
            parser = Parser()
            parser.language = Language(lang_map[lang])
            return parser
    except Exception:
        pass

    return None

def ast_to_tree_string(node, source_code: bytes, indent=0, max_depth=8) -> str:
    if indent > max_depth:
        return ""
    result = "  " * indent + f"|- {node.type}"
    if node.child_count == 0:
        text = source_code[node.start_byte:node.end_byte].decode('utf-8', errors='ignore')
        if len(text) < 50 and '\n' not in text:
            result += f": `{text}`"
    result += f" (line {node.start_point[0] + 1})\n"
    for child in node.children:
        result += ast_to_tree_string(child, source_code, indent + 1, max_depth)
    return result

def analyze_file_with_treesitter(file_path: Path, repo_path: Path) -> dict:
    if not TREE_SITTER_AVAILABLE:
        return {
            'available': False,
            'ast_tree': "Tree-sitter not installed",
            'findings': [],
            'node_count': 0,
            'depth': 0,
        }

    lang = get_language(file_path)
    parser = get_parser_for_language(lang)
    if not parser:
        return {
            'available': False,
            'ast_tree': f"No parser for {lang}",
            'findings': [],
            'node_count': 0,
            'depth': 0,
        }

    try:
        source_code = file_path.read_bytes()
        tree = parser.parse(source_code)
        ast_tree = ast_to_tree_string(tree.root_node, source_code, max_depth=8)
        findings = check_dangerous_functions(
            tree.root_node,
            source_code,
            str(file_path.relative_to(repo_path))
        )

        def count_nodes(node):
            return 1 + sum(count_nodes(child) for child in node.children)

        def get_depth(node):
            return 1 if node.child_count == 0 else 1 + max(get_depth(child) for child in node.children)

        return {
            'available': True,
            'ast_tree': ast_tree,
            'findings': findings,
            'node_count': count_nodes(tree.root_node),
            'depth': get_depth(tree.root_node),
            'root_type': tree.root_node.type,
        }
    except Exception as e:
        return {
            'available': False,
            'ast_tree': f"Error: {e}",
            'findings': [],
            'node_count': 0,
            'depth': 0,
        }

def check_dangerous_functions(node, source_code: bytes, file_path: str) -> list:
    findings = []
    dangerous_patterns = {
        'Python': {
            'eval': {'cwe': 'CWE-95', 'severity': 'CRITICAL', 'desc': 'Arbitrary code execution via eval()'},
            'exec': {'cwe': 'CWE-95', 'severity': 'CRITICAL', 'desc': 'Arbitrary code execution via exec()'},
            'compile': {'cwe': 'CWE-95', 'severity': 'HIGH', 'desc': 'Dynamic code compilation'},
            '__import__': {'cwe': 'CWE-94', 'severity': 'HIGH', 'desc': 'Dynamic import code injection'},
            'pickle.loads': {'cwe': 'CWE-502', 'severity': 'HIGH', 'desc': 'Insecure deserialization'},
            'yaml.load': {'cwe': 'CWE-502', 'severity': 'HIGH', 'desc': 'Insecure YAML deserialization'},
            'os.system': {'cwe': 'CWE-78', 'severity': 'HIGH', 'desc': 'Command injection via os.system'},
        },
        'C': {
            'strcpy': {'cwe': 'CWE-120', 'severity': 'HIGH', 'desc': 'Buffer overflow - use strncpy'},
            'gets': {'cwe': 'CWE-120', 'severity': 'CRITICAL', 'desc': 'Never use gets()'},
            'sprintf': {'cwe': 'CWE-120', 'severity': 'HIGH', 'desc': 'Buffer overflow - use snprintf'},
            'strcat': {'cwe': 'CWE-120', 'severity': 'MEDIUM', 'desc': 'Buffer overflow - use strncat'},
            'scanf': {'cwe': 'CWE-120', 'severity': 'MEDIUM', 'desc': 'Input validation risk'},
        },
        'JavaScript': {
            'eval': {'cwe': 'CWE-95', 'severity': 'CRITICAL', 'desc': 'Code injection via eval()'},
            'innerHTML': {'cwe': 'CWE-79', 'severity': 'HIGH', 'desc': 'Cross-site scripting via innerHTML'},
            'document.write': {'cwe': 'CWE-79', 'severity': 'MEDIUM', 'desc': 'Cross-site scripting risk'},
            'dangerouslySetInnerHTML': {'cwe': 'CWE-79', 'severity': 'HIGH', 'desc': 'React cross-site scripting'},
        },
        'Java': {
            'Runtime.exec': {'cwe': 'CWE-78', 'severity': 'HIGH', 'desc': 'Command injection'},
            'ProcessBuilder': {'cwe': 'CWE-78', 'severity': 'HIGH', 'desc': 'Command injection'},
            'readObject': {'cwe': 'CWE-502', 'severity': 'HIGH', 'desc': 'Insecure deserialization'},
        },
    }

    def traverse(n):
        if n.type in ['call', 'call_expression', 'function_call']:
            func_name = None
            for child in n.children:
                if child.type in ['identifier', 'attribute', 'member_expression', 'field_expression']:
                    func_name = source_code[child.start_byte:child.end_byte].decode('utf-8', errors='ignore')
                    break
            if func_name:
                lang = get_language(Path(file_path))
                if lang in dangerous_patterns:
                    for pattern, info in dangerous_patterns[lang].items():
                        if pattern in func_name:
                            findings.append({
                                'Source': 'Tree-sitter Structural Analysis',
                                'File Path': file_path,
                                'Line': str(n.start_point[0] + 1),
                                'Vulnerability': f"Dangerous: {func_name} - {info['desc']}",
                                'Severity': info['severity'],
                                'CWE': info['cwe'],
                                'Zero-Day Risk': 'Medium',
                            })
        for child in n.children:
            traverse(child)

    traverse(node)
    return findings

def run_treesitter_analysis(repo_path: Path) -> pd.DataFrame:
    if not TREE_SITTER_AVAILABLE:
        return pd.DataFrame()
    files = [
        f for f in repo_path.rglob('*')
        if f.is_file() and f.suffix.lower() in ['.c', '.h', '.cpp', '.hpp', '.py', '.java', '.js']
    ]
    all_findings = []
    for file_path in files:
        try:
            analysis = analyze_file_with_treesitter(file_path, repo_path)
            st.session_state.ast_cache[str(file_path.relative_to(repo_path))] = analysis
            all_findings.extend(analysis['findings'])
        except Exception:
            continue
    return pd.DataFrame(all_findings)

# ==================== SEMGREP ANALYSIS ====================

def run_semgrep(repo_path: Path) -> pd.DataFrame:
    output = Path(repo_path) / "semgrep_results.json"
    configs = ["p/security-audit", "p/cwe-top-25", "p/secrets"]
    cmd = ["semgrep", "scan", "--json", "-o", str(output)]
    for c in configs:
        cmd.extend(["--config", c])
    cmd.append(str(repo_path))
    try:
        subprocess.run(cmd, check=True, capture_output=True, text=True, timeout=300)
        with open(output, 'r') as f:
            results = json.load(f).get("results", [])
        findings = []
        for res in results:
            cwe = res["extra"].get("metadata", {}).get("cwe", "N/A")
            if isinstance(cwe, list):
                cwe = ', '.join(str(c) for c in cwe) if cwe else "N/A"
            findings.append({
                "Source": "Semgrep Static Analysis",
                "File Path": res["path"].replace(str(repo_path) + os.sep, ""),
                "Line": str(res["start"]["line"]),
                "Vulnerability": res["extra"]["message"],
                "Severity": res["extra"]["severity"].upper(),
                "CWE": str(cwe or "N/A"),
                "Zero-Day Risk": "Low",
            })
        return pd.DataFrame(findings)
    except Exception as e:
        st.error(f"Semgrep failed: {e}")
        return pd.DataFrame()

# ==================== AI ANALYSIS ====================

def run_llm_analysis(repo_path: Path) -> pd.DataFrame:
    files = [
        f for f in repo_path.rglob('*')
        if f.is_file() and f.suffix.lower() in [
            '.c', '.h', '.cpp', '.hpp', '.py', '.java', '.js', '.php'
        ]
    ]
    all_findings = []
    for i in range(0, len(files), BATCH_SIZE):
        batch = files[i:i + BATCH_SIZE]
        payload = []
        for fp in batch:
            try:
                payload.append({
                    "id": str(fp),
                    "code": fp.read_text(encoding='utf-8', errors='ignore'),
                    "language": get_language(fp),
                })
            except Exception:
                continue
        if not payload:
            continue
        try:
            resp = requests.post(
                f"{API_ENDPOINT}/analyze_batch",
                json=payload,
                timeout=300,
            )
            resp.raise_for_status()
            for file_id, analysis in resp.json().get('llm_analyses', {}).items():
                if "vulnerable" in analysis.lower() or "cwe-" in analysis.lower():
                    cwe_id = "N/A"
                    if "cwe-" in analysis.lower():
                        try:
                            cwe_id = "CWE-" + analysis.lower().split('cwe-')[1].split('.')[0].split()[0].strip()
                        except Exception:
                            pass
                    finding = {
                        "Source": "AI Zero-Day Detection",
                        "File Path": str(Path(file_id).relative_to(repo_path)),
                        "Line": "Multiple",
                        "Vulnerability": analysis[:200],
                        "Severity": "HIGH",
                        "CWE": str(cwe_id),
                        "Zero-Day Risk": "High",
                    }
                    all_findings.append(enrich_llm_finding_with_ai(finding))
        except Exception:
            continue
    return pd.DataFrame(all_findings)

# ==================== FILE UPLOAD HANDLER ====================

def extract_uploaded_file(uploaded_file, extract_path: Path) -> bool:
    """Extract uploaded archive file to the specified path."""
    try:
        file_extension = Path(uploaded_file.name).suffix.lower()
        
        if file_extension == '.zip':
            with zipfile.ZipFile(io.BytesIO(uploaded_file.getbuffer()), 'r') as zip_ref:
                zip_ref.extractall(extract_path)
            return True
        elif file_extension in ['.tar', '.gz', '.tgz', '.tar.gz', '.tar.bz2', '.tbz2']:
            # Determine the mode based on extension
            if file_extension in ['.tar.gz', '.tgz']:
                mode = 'r:gz'
            elif file_extension in ['.tar.bz2', '.tbz2']:
                mode = 'r:bz2'
            else:
                mode = 'r'
            
            with tarfile.open(fileobj=io.BytesIO(uploaded_file.getbuffer()), mode=mode) as tar_ref:
                tar_ref.extractall(extract_path)
            return True
        else:
            st.error(f"Unsupported file format: {file_extension}. Please upload .zip, .tar, .tar.gz, or .tar.bz2")
            return False
    except Exception as e:
        st.error(f"Failed to extract file: {str(e)}")
        return False

# ==================== SCAN ORCHESTRATOR ====================

def perform_full_scan(repo_url: str = None, repo_path: Path = None) -> pd.DataFrame:
    if repo_path is None:
        temp_dir = tempfile.mkdtemp()
        repo_path = Path(temp_dir)
        
        if repo_url:
            st.session_state.ast_cache = {}

            with st.status("Cloning repository...", expanded=True) as status:
                try:
                    git.Repo.clone_from(repo_url, repo_path, depth=1)
                    status.update(label="Repository cloned", state="complete")
                except Exception as e:
                    status.update(label="Clone failed", state="error")
                    st.error(f"Clone failed: {e}")
                    return pd.DataFrame()
        else:
            st.error("No repository URL or file path provided")
            return pd.DataFrame()
    
    st.session_state.repo_path = str(repo_path)
    st.session_state.ast_cache = {}

    with st.status("Running security scans...", expanded=True) as status:
        st.write("Running Semgrep static analysis...")
        semgrep_df = run_semgrep(repo_path)
        st.write("Running Tree-sitter structural analysis...")
        treesitter_df = run_treesitter_analysis(repo_path)
        st.write("Running AI zero-day detection...")
        llm_df = run_llm_analysis(repo_path)
        status.update(label="All scans complete", state="complete")

    all_findings = pd.concat([semgrep_df, treesitter_df, llm_df], ignore_index=True)
    all_findings = normalize_dataframe(all_findings)

    # CWE enrichment
    if not all_findings.empty and CWE_CLASSIFIER_AVAILABLE:
        with st.status("Classifying CWEs with AI...", expanded=False) as status:
            all_findings = enrich_findings_with_cwe(all_findings)
            status.update(label="CWE classification complete", state="complete")

    if not all_findings.empty:
        all_findings['severity_score'] = all_findings['Severity'].map(SEVERITY_ORDER).fillna(99)
        all_findings = all_findings.sort_values('severity_score').drop(columns=['severity_score'])

        # Save to database
        if DB_AVAILABLE:
            try:
                detection_score = calculate_detection_score(all_findings)
                findings_dict = all_findings.to_dict('records')
                for f in findings_dict:
                    if f.get('CWE') and len(f['CWE']) > 20:
                        f['CWE'] = f['CWE'][:17] + '...'

                scan_id = db.save_scan_result(repo_url, findings_dict, detection_score)
                st.session_state.current_scan_id = scan_id
                st.success(f"Scan saved to database (ID: {scan_id})")
            except Exception as e:
                st.warning(f"Could not save to database: {str(e)[:100]}")

    return all_findings

# ==================== SIDEBAR + GLOBAL HEADER ====================

def draw_sidebar():
    with st.sidebar:
        st.title("FOSS-CHERUB")

        if st.session_state.repo_url:
            st.caption("Current repository")
            st.code(st.session_state.repo_url, language="text")

        st.markdown("### Status")
        if TREE_SITTER_AVAILABLE:
            st.success("Tree-sitter enabled")
        else:
            st.warning("Tree-sitter disabled")

        if DB_AVAILABLE:
            st.success("Database online")
        else:
            st.warning("Database offline")

        st.markdown("### View")
        view_options = {
            "New Scan": "scan",
            "Results": "results",
            "Finding Detail": "detail",
            "Scan History": "history",
        }
        reverse_map = {v: k for k, v in view_options.items()}
        current_label = reverse_map.get(st.session_state.view, "New Scan")

        selected_label = st.radio(
            "Navigate",
            options=list(view_options.keys()),
            index=list(view_options.keys()).index(current_label),
        )
        st.session_state.view = view_options[selected_label]

def draw_global_header():
    with st.container():
        left, right = st.columns([3, 1])
        with left:
            st.markdown("## FOSS-CHERUB Security Scanner")
            st.caption(
                "FOSS-friendly static, structural and AI-based security scanner.\n"
                "Semgrep, Tree-sitter, Qwen-based analysis, CVE/CWE database integration."
            )
        with right:
            if DB_AVAILABLE:
                stats = db.get_statistics()
                st.metric("Total scans", stats.get("scans_count", 0))
            else:
                st.metric("Database", "Offline")
    st.markdown("---")

# ==================== VIEW 1: SCAN ====================

def draw_scan_view():
    spacer_left, center, spacer_right = st.columns([1, 2, 1])
    with center:
        # Tabs for Git repository or file upload
        tab_git, tab_upload = st.tabs(["Git Repository", "Upload File"])
        
        # ==================== GIT REPOSITORY TAB ====================
        with tab_git:
            with st.container(border=True):
                st.markdown("### Analyze Git Repository")
                st.caption(
                    "Paste a public GitHub repository URL. FOSS-CHERUB will clone it, run Semgrep, "
                    "Tree-sitter structural analysis, AI zero-day detection, and enrich results with CWE/CVE data."
                )

                repo_url = st.text_input(
                    "Repository URL",
                    value=st.session_state.repo_url,
                    placeholder="https://github.com/username/repository",
                )

                col_a, col_b = st.columns(2)
                with col_a:
                    if TREE_SITTER_AVAILABLE:
                        st.info("Tree-sitter: enabled")
                    else:
                        st.warning("Tree-sitter: disabled")
                with col_b:
                    if DB_AVAILABLE:
                        stats = db.get_statistics()
                        st.info(
                            f"Database: {stats['cve_count']:,} CVEs, {stats['cwe_count']:,} CWEs"
                        )
                    else:
                        st.warning("Database: offline")

                st.markdown("")

                scan_col, history_col = st.columns([2, 1])
                with scan_col:
                    if st.button("Run full security scan", type="primary", use_container_width=True, key="git_scan"):
                        if not repo_url:
                            st.warning("Please enter a repository URL.")
                            return
                        st.session_state.repo_url = repo_url
                        results = perform_full_scan(repo_url=repo_url)
                        if results.empty:
                            st.success("No vulnerabilities detected.")
                            return
                        st.session_state.results = results
                        st.session_state.detection_score = calculate_detection_score(results)
                        st.session_state.view = 'results'
                        st.rerun()
                with history_col:
                    if DB_AVAILABLE and st.button("View scan history", use_container_width=True):
                        st.session_state.view = 'history'
                        st.rerun()

            st.markdown("")
            st.caption("Tip: Start with a smaller repository to evaluate findings and performance.")
        
        # ==================== FILE UPLOAD TAB ====================
        with tab_upload:
            with st.container(border=True):
                st.markdown("### Upload Source Code")
                st.caption(
                    "Upload a ZIP or TAR archive containing source code. "
                    "FOSS-CHERUB will extract and analyze it with Semgrep, "
                    "Tree-sitter, AI detection, and CWE/CVE enrichment."
                )

                uploaded_file = st.file_uploader(
                    "Choose a file (ZIP, TAR, TAR.GZ, or TAR.BZ2)",
                    type=["zip", "tar", "gz", "tgz", "tbz2", "bz2"],
                    help="Maximum file size depends on your Streamlit configuration"
                )

                col_a, col_b = st.columns(2)
                with col_a:
                    if TREE_SITTER_AVAILABLE:
                        st.info("Tree-sitter: enabled")
                    else:
                        st.warning("Tree-sitter: disabled")
                with col_b:
                    if DB_AVAILABLE:
                        stats = db.get_statistics()
                        st.info(
                            f"Database: {stats['cve_count']:,} CVEs, {stats['cwe_count']:,} CWEs"
                        )
                    else:
                        st.warning("Database: offline")

                st.markdown("")

                if uploaded_file:
                    if st.button("Scan uploaded file", type="primary", use_container_width=True, key="file_scan"):
                        temp_dir = tempfile.mkdtemp()
                        extract_path = Path(temp_dir)
                        
                        with st.status(f"Extracting {uploaded_file.name}...", expanded=True) as status:
                            if extract_uploaded_file(uploaded_file, extract_path):
                                status.update(label=f"{uploaded_file.name} extracted", state="complete")
                                st.session_state.repo_url = f"Uploaded: {uploaded_file.name}"
                                
                                results = perform_full_scan(repo_path=extract_path)
                                if results.empty:
                                    st.success("No vulnerabilities detected.")
                                    return
                                st.session_state.results = results
                                st.session_state.detection_score = calculate_detection_score(results)
                                st.session_state.view = 'results'
                                st.rerun()
                            else:
                                status.update(label="Extraction failed", state="error")
                else:
                    st.info("ðŸ‘† Upload a file to begin scanning")

# ==================== VIEW 2: RESULTS ====================

def draw_results_view():
    if st.session_state.results is None or st.session_state.results.empty:
        st.info("No results available yet. Run a scan first.")
        return

    top_left, top_mid, _ = st.columns([1, 3, 1])
    with top_left:
        if st.button("New scan"):
            st.session_state.view = 'scan'
            st.session_state.results = None
            st.session_state.selected_finding = None
            if st.session_state.repo_path and Path(st.session_state.repo_path).exists():
                try:
                    shutil.rmtree(st.session_state.repo_path)
                except Exception:
                    pass
            st.rerun()
    with top_mid:
        st.markdown(f"### Results for `{st.session_state.repo_url}`")

    st.markdown("---")

    score = st.session_state.detection_score
    critical_high = len(
        st.session_state.results[
            st.session_state.results['Severity'].isin(['CRITICAL', 'HIGH'])
        ]
    )
    zero_day_high = len(
        st.session_state.results[st.session_state.results['Zero-Day Risk'] == 'High']
    )

    s1, s2, s3, s4 = st.columns(4)
    with s1:
        st.metric("Vendors flagged", f"{score['detected']}/{score['total']}")
    with s2:
        st.metric("Critical / High", critical_high)
    with s3:
        st.metric("High zero-day risk", zero_day_high)
    with s4:
        st.metric("Total findings", len(st.session_state.results))

    st.markdown("")

    with st.container(border=True):
        st.markdown("#### Filters")
        fc1, fc2, fc3, fc4 = st.columns(4)
        with fc1:
            st.session_state.filters['severity'] = st.multiselect(
                "Severity",
                options=['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'INFO', 'WARNING'],
                default=st.session_state.filters['severity'],
            )
        with fc2:
            sources = ['All', 'Semgrep', 'Tree-sitter', 'AI']
            st.session_state.filters['source'] = st.selectbox(
                "Source",
                options=sources,
                index=sources.index(st.session_state.filters['source'])
                if st.session_state.filters['source'] in sources else 0,
            )
        with fc3:
            risks = ['All', 'High', 'Medium', 'Low']
            st.session_state.filters['zero_day_risk'] = st.selectbox(
                "Zero-Day Risk",
                options=risks,
                index=risks.index(st.session_state.filters['zero_day_risk']),
            )
        with fc4:
            st.session_state.filters['search'] = st.text_input(
                "Search",
                value=st.session_state.filters['search'],
                placeholder="File path, CWE, keyword...",
            )

    st.markdown("")

    filtered = apply_filters(st.session_state.results)
    st.markdown(
        f"#### Detected vulnerabilities ({len(filtered)} of {len(st.session_state.results)})"
    )

    if filtered.empty:
        st.info("No results match your filters.")
        return

    results = filtered.copy()
    results.insert(0, 'ID', range(1, len(results) + 1))

    for idx, row in results.iterrows():
        with st.container(border=True):
            h1, h2, h3, h4 = st.columns([0.7, 2.3, 1.2, 1.2])
            with h1:
                st.markdown(f"**#{row['ID']}**")
            with h2:
                st.markdown(f"`{row['File Path']}`")
                short_vuln = row['Vulnerability'][:120]
                if len(row['Vulnerability']) > 120:
                    short_vuln += "..."
                st.caption(short_vuln)
            with h3:
                st.markdown(f"**Severity:** {row['Severity']}")
                st.caption(f"CWE: {row['CWE']}")
            with h4:
                st.markdown(f"Zero-day risk: {row['Zero-Day Risk']}")
                if st.button(
                    "Review",
                    key=f"review_{idx}_{row['ID']}",
                    use_container_width=True,
                ):
                    st.session_state.selected_finding = row.to_dict()
                    st.session_state.view = 'detail'
                    st.rerun()

# ==================== VIEW 3: DETAIL ====================

def draw_detail_view():
    if st.session_state.selected_finding is None:
        st.info("No finding selected. Go to Results and click Review.")
        return

    top_left, top_mid, _ = st.columns([1, 3, 1])
    with top_left:
        if st.button("Back to results"):
            st.session_state.view = 'results'
            st.rerun()
    with top_mid:
        st.markdown("### Finding detail")

    finding = st.session_state.selected_finding
    st.markdown("---")

    sev_colors = {
        'CRITICAL': '#ff0000',
        'HIGH': '#ff8800',
        'MEDIUM': '#ffaa00',
        'LOW': '#88ff88',
    }
    color = sev_colors.get(finding['Severity'], '#888888')
    st.markdown(
        f"## <span style='color: {color};'>Severity: {finding['Severity']}</span> - {finding['CWE']}",
        unsafe_allow_html=True,
    )
    st.markdown(f"#### {finding['Vulnerability']}")
    st.markdown("---")

    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("File", finding['File Path'])
        st.metric("Line", finding['Line'])
    with c2:
        st.metric("Source", finding['Source'])
        st.metric("Zero-day risk", finding['Zero-Day Risk'])
    with c3:
        st.metric("Severity", finding['Severity'])
        st.metric("CWE", finding['CWE'])

    st.markdown("---")

    tab_db, tab_ast, tab_ai = st.tabs(
        ["CVE/CWE intelligence", "AST and structural view", "AI mitigation and code context"]
    )

    # Database / CWE tab
    with tab_db:
        if DB_AVAILABLE and finding['CWE'] not in ['N/A', '', 'nan']:
            st.markdown("### CWE and related CVEs")
            cwe_id = finding['CWE'].split(',')[0].strip()
            if cwe_id.startswith('CWE-'):
                cwe_details = db.get_cwe_details(cwe_id)
                if cwe_details:
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        st.markdown(f"#### {cwe_details['name']}")
                        st.markdown(cwe_details['description'][:600] + "...")
                    with col2:
                        if cwe_details['typical_severity']:
                            st.metric("Typical severity", cwe_details['typical_severity'])

                    st.markdown("#### Related CVEs")
                    related_cves = db.search_cves_by_cwe(cwe_id, limit=5)
                    if related_cves:
                        for cve in related_cves:
                            with st.expander(
                                f"{cve['cve_id']} - CVSS {cve['cvss_base_score']} "
                                f"({cve['cvss_base_severity']})"
                            ):
                                st.markdown(f"**Description:** {cve['description'][:400]}...")
                                if cve['published_date']:
                                    st.markdown(f"**Published:** {cve['published_date']}")
                                if cve['cvss_vector_string']:
                                    st.code(cve['cvss_vector_string'], language='text')
                    else:
                        st.info("No related CVEs found in database for this CWE.")
                else:
                    st.info("CWE details not found in database.")
            else:
                st.info("CWE format not recognized.")
        else:
            st.info("Database unavailable or CWE not set for this finding.")

    # AST tab
    with tab_ast:
        st.markdown("### Tree-sitter AST analysis")
        if TREE_SITTER_AVAILABLE and finding['File Path'] in st.session_state.ast_cache:
            ast_data = st.session_state.ast_cache[finding['File Path']]
            if ast_data['available']:
                c1, c2, c3, c4 = st.columns(4)
                with c1:
                    st.metric("Nodes", ast_data['node_count'])
                with c2:
                    st.metric("Tree depth", ast_data['depth'])
                with c3:
                    st.metric("Root type", ast_data['root_type'])
                with c4:
                    st.metric("Findings in file", len(ast_data['findings']))

                with st.expander("View abstract syntax tree (AST)", expanded=False):
                    st.code(ast_data['ast_tree'], language='text')
                    st.caption("Parsed structural view of the file.")

                if ast_data['findings']:
                    st.markdown("#### Tree-sitter findings in this file")
                    for idx, ts_finding in enumerate(ast_data['findings'], 1):
                        st.markdown(
                            f"**{idx}. Line {ts_finding['Line']}:** {ts_finding['Vulnerability']}"
                        )
                        st.caption(
                            f"CWE: {ts_finding['CWE']} Â· Severity: {ts_finding['Severity']}"
                        )
                        st.markdown("---")
            else:
                st.info(f"Tree-sitter analysis unavailable: {ast_data['ast_tree']}")
        else:
            st.info("No Tree-sitter data available for this file.")

    # AI Mitigation tab
    with tab_ai:
        st.markdown("### AI mitigation and code context")

        file_content = ""
        if st.session_state.repo_path:
            try:
                fp = Path(st.session_state.repo_path) / finding['File Path']
                if fp.exists():
                    file_content = fp.read_text(errors='ignore')
            except Exception:
                file_content = ""

        with st.spinner("Requesting mitigation from AI backend..."):
            try:
                resp = requests.post(
                    f"{API_ENDPOINT}/get_mitigation",
                    json={
                        "file_content": file_content if file_content else f"File: {finding['File Path']}",
                        "line_number": int(finding['Line']) if str(finding['Line']).isdigit() else 1,
                        "vulnerability": finding['Vulnerability'],
                        "language": get_language(Path(finding['File Path'])),
                    },
                    timeout=120,
                )
                if resp.ok:
                    mitigation = resp.json().get('mitigation', 'No mitigation available.')
                    st.markdown("#### Recommended mitigation")
                    st.markdown(mitigation)
                    st.download_button(
                        label="Download mitigation notes",
                        data=mitigation,
                        file_name=f"fix_{finding['CWE']}_{Path(finding['File Path']).name}.md",
                        mime="text/markdown",
                    )
                else:
                    st.error(f"Mitigation request failed: {resp.status_code}")
            except Exception as e:
                st.error(f"Error while requesting mitigation: {str(e)[:200]}")

        st.markdown("---")

        with st.expander("Code context"):
            st.markdown(
                f"**Vulnerability:** {finding['Vulnerability']}\n\n"
                f"**File:** `{finding['File Path']}`  \n"
                f"**Line:** `{finding['Line']}`  \n"
                f"**Source:** {finding['Source']}  \n"
                f"**CWE:** "
                f"[{finding['CWE']}]("
                f"https://cwe.mitre.org/data/definitions/"
                f"{finding['CWE'].replace('CWE-', '').replace(',', '').split()[0]}.html"
                f")"
            )

            if file_content:
                st.markdown("#### Nearby code")
                lines = file_content.split('\n')
                if str(finding['Line']).isdigit():
                    ln = int(finding['Line'])
                    start = max(0, ln - 5)
                    end = min(len(lines), ln + 5)
                    context = '\n'.join([f"{i + 1:4d}: {lines[i]}" for i in range(start, end)])
                    st.code(context, language=get_language(Path(finding['File Path'])).lower())
                else:
                    st.code(
                        file_content[:2000],
                        language=get_language(Path(finding['File Path'])).lower()
                    )

# ==================== VIEW 4: HISTORY ====================

def draw_history_view():
    st.header("Scan history")

    if not DB_AVAILABLE:
        st.warning("Database not available.")
        if st.button("Back to scanner"):
            st.session_state.view = 'scan'
            st.rerun()
        return

    scans = db.get_scan_history(limit=50)

    if not scans:
        st.info("No scans recorded yet.")
        if st.button("Back to scanner"):
            st.session_state.view = 'scan'
            st.rerun()
        return

    for scan in scans:
        with st.container(border=True):
            st.markdown(
                f"**Repository:** {scan['repository_url']}  "
                f"({scan['scan_date']})"
            )
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Critical", scan['critical_count'])
            with col2:
                st.metric("High", scan['high_count'])
            with col3:
                st.metric("Medium", scan['medium_count'])
            with col4:
                st.metric("Low", scan['low_count'])

            st.markdown(f"**Total findings:** {scan['total_findings']}")

    if st.button("Back to scanner"):
        st.session_state.view = 'scan'
        st.rerun()

# ==================== MAIN ====================

st.markdown(
    """
<style>
.stMetric {
    background: #1e1e1e;
    padding: 10px;
    border-radius: 5px;
}
.stButton button {
    border-radius: 5px;
}
</style>
""",
    unsafe_allow_html=True,
)

draw_sidebar()
draw_global_header()

if st.session_state.view == 'scan':
    draw_scan_view()
elif st.session_state.view == 'results':
    draw_results_view()
elif st.session_state.view == 'detail':
    draw_detail_view()
elif st.session_state.view == 'history':
    draw_history_view()
